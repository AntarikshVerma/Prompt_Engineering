{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwsm92B/u5R7OvKZ0EMu9p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntarikshVerma/Prompt_Engineering/blob/main/prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prompting Principles\n",
        "1. Principle 1: Write clear and specific instructions\n",
        "2. Principle 2: Give the model time to “think”\n",
        "\n",
        "\n",
        "##Tactics"
      ],
      "metadata": {
        "id": "rRc_-khYgby0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Azure OPEN AI Setup"
      ],
      "metadata": {
        "id": "aO3S51YWbqqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "neatd1MhiZST",
        "outputId": "116e16d3-9fff-433f-cf93-629d47298976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.37.2-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.1/337.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "open_ai_key=userdata.get('OPENAI_API_KEY')\n",
        "open_ai_base=userdata.get('OPEN_API_URL')\n",
        "api_version=\"2023-07-01-preview\""
      ],
      "metadata": {
        "id": "ixLqxF5Jb2FD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai = AzureOpenAI(\n",
        "            api_version=api_version,\n",
        "            azure_endpoint=open_ai_base,\n",
        "            api_key=open_ai_key,\n",
        "        )"
      ],
      "metadata": {
        "id": "rY6unm6ucACG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-35-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "b370gLtWdZ2D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "###Delimiters can be anything like: ```, \"\"\", < >, <tag> </tag>, :"
      ],
      "metadata": {
        "id": "cE-bRGKhhRyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaDw1UUjdzol",
        "outputId": "7b53da8b-eef6-4c6b-849d-6628bdd9d7a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is important to provide clear and specific instructions to guide the model towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, and longer prompts can provide more clarity and context for the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tactic 2: Ask for a structured output\n",
        "####JSON, HTML"
      ],
      "metadata": {
        "id": "EsMzzPCWhlxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up book titles along \\\n",
        "with their authors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "gH1DeEu5fjBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94466a82-59dd-43cb-c56e-1f7aa01e24c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"books\": [\n",
            "    {\n",
            "      \"book_id\": 1,\n",
            "      \"title\": \"The Midnight Garden\",\n",
            "      \"author\": \"Eleanor Black\",\n",
            "      \"genre\": \"Fantasy\"\n",
            "    },\n",
            "    {\n",
            "      \"book_id\": 2,\n",
            "      \"title\": \"The Forgotten Symphony\",\n",
            "      \"author\": \"Lucas Hart\",\n",
            "      \"genre\": \"Mystery\"\n",
            "    },\n",
            "    {\n",
            "      \"book_id\": 3,\n",
            "      \"title\": \"Echoes of Eternity\",\n",
            "      \"author\": \"Aria Nightingale\",\n",
            "      \"genre\": \"Romance\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8WtSbXFiH5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}